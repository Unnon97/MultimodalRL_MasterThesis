# MultimodalRL_MasterThesis
Repository providing information about my Master Thesis project developed during my work at Fraunhofer IPA

## Topic: 
Combining Visual Servoing and Force Control with Reinforcement Learning for Gear Assembly

## Abstract:
The deployment of robots has been steadily growing worldwide, but their use in assembly tasks remains limited compared to other application areas. The high sensitivity to tolerances required for assembly-related tasks is a significant factor impeding this growth. To implement robustness in these robots, numerous researchers leverage learning-based systems equipped with sensors, such as cameras and force-torque sensors. Relying solely on individual sensors can limit adaptability and robustness, leading to the need for multimodal fusion-based approaches that use different sensor modalities. Nevertheless, implementing such a system in operational scenarios involves obtaining datasets, training, and deploying the learning-based system. This creates a significant barrier to wide-scale adoption due to the shortage of skilled personnel capable of performing these tasks. So, to deal with this restriction, we present an alternative pipeline to train and deploy an RL model using a mini-simulation setup built from actual sensor observations. This system can be used by technicians operating robotic manipulators as it streamlines the drift calibration process by minimizing technician effort and reducing machine downtime to enable quick deployment.
